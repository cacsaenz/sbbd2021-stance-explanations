{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics calculation\n",
    "\n",
    "Based on attentions, tf-idf, etc..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "STOPWORDS = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "FOLDER = './results/'\n",
    "\n",
    "COUNTS = {}\n",
    "for i, row in pd.read_csv(f'{FOLDER}/result_counts.csv').iterrows():\n",
    "    COUNTS[row['name']] = row['count']\n",
    "    \n",
    "token_metrics = []\n",
    "COUNTS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Words metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_metrics = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Attention (General and by group)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_attention_df = pd.read_csv(f'{FOLDER}/words_attention.csv', sep=';')\n",
    "words_attention_df['tokens'] = words_attention_df.tokens.apply(lambda x: str(x).split(' '))\n",
    "words_attention_df = words_attention_df.loc[\n",
    "    (words_attention_df.word.str.len() > 1) &\\\n",
    "    (~words_attention_df.word.isin(STOPWORDS)) &\\\n",
    "    (~words_attention_df.word.isin(list(string.punctuation)))\n",
    "] # Remove words in stopwords\n",
    "words_attention_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, row in words_attention_df.iterrows():\n",
    "    if row.word not in words_metrics:\n",
    "        words_metrics[row.word] = {\n",
    "            'absolute': 0.0,\n",
    "            'absolute_correct': 0.0,\n",
    "            'absolute_incorrect': 0.0,\n",
    "            \n",
    "            'relative': 0.0,\n",
    "            'relative_correct': 0.0,\n",
    "            'relative_incorrect': 0.0,\n",
    "            \n",
    "            'antichina_absolute': 0.0,\n",
    "            'antichina_absolute_correct': 0.0,\n",
    "            'antichina_absolute_incorrect': 0.0,\n",
    "            'antichina_relative': 0.0,\n",
    "            'antichina_relative_correct': 0.0,\n",
    "            'antichina_relative_incorrect': 0.0,\n",
    "            \n",
    "            'antivacina_absolute': 0.0,\n",
    "            'antivacina_absolute_correct': 0.0,\n",
    "            'antivacina_absolute_incorrect': 0.0,\n",
    "            'antivacina_relative': 0.0,\n",
    "            'antivacina_relative_correct': 0.0,\n",
    "            'antivacina_relative_incorrect': 0.0,\n",
    "            \n",
    "            'provacina_absolute': 0.0,\n",
    "            'provacina_absolute_correct': 0.0,\n",
    "            'provacina_absolute_incorrect': 0.0,\n",
    "            'provacina_relative': 0.0,\n",
    "            'provacina_relative_correct': 0.0,\n",
    "            'provacina_relative_incorrect': 0.0,\n",
    "            \n",
    "            'tfidf': 0.0,\n",
    "            \n",
    "            'antichina_tfidf': 0.0,\n",
    "            'antivacina_tfidf': 0.0,\n",
    "            'provacina_tfidf': 0.0,\n",
    "            \n",
    "            'antichina_tfidf_correct': 0.0,\n",
    "            'antivacina_tfidf_correct': 0.0,\n",
    "            'provacina_tfidf_correct': 0.0,\n",
    "            \n",
    "            'antichina_tfidf_incorrect': 0.0,\n",
    "            'antivacina_tfidf_incorrect': 0.0,\n",
    "            'provacina_tfidf_incorrect': 0.0,\n",
    "        }\n",
    "    \n",
    "    words_metrics[row.word]['absolute'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_correct_w + row.antivacina_correct_w + row.provacina_correct_w +\\\n",
    "                row.antichina_incorrect_w + row.antivacina_incorrect_w + row.provacina_incorrect_w\n",
    "            ) / COUNTS['total'] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "        ) * 100 \n",
    "    )\n",
    "    \n",
    "    words_metrics[row.word]['absolute_correct'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_correct_w + row.antivacina_correct_w + row.provacina_correct_w\n",
    "            ) / COUNTS['total'] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "        ) * 100 \n",
    "    )\n",
    "    \n",
    "    words_metrics[row.word]['absolute_incorrect'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_incorrect_w + row.antivacina_incorrect_w + row.provacina_incorrect_w\n",
    "            ) / COUNTS['total'] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "        ) * 100 \n",
    "    )\n",
    "    \n",
    "    words_metrics[row.word]['relative'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_correct_w + row.antivacina_correct_w + row.provacina_correct_w +\\\n",
    "                row.antichina_incorrect_w + row.antivacina_incorrect_w + row.provacina_incorrect_w\n",
    "            ) / (\n",
    "                row.antichina_correct_n + row.antivacina_correct_n + row.provacina_correct_n +\\\n",
    "                row.antichina_incorrect_n + row.antivacina_incorrect_n + row.provacina_incorrect_n\n",
    "            )\n",
    "        ) * 100 \n",
    "    )\n",
    "    \n",
    "    words_metrics[row.word]['relative_correct'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_correct_w + row.antivacina_correct_w + row.provacina_correct_w\n",
    "            ) / (\n",
    "                row.antichina_correct_n + row.antivacina_correct_n + row.provacina_correct_n +\\\n",
    "                row.antichina_incorrect_n + row.antivacina_incorrect_n + row.provacina_incorrect_n\n",
    "            )\n",
    "        ) * 100 \n",
    "    )  \n",
    "    \n",
    "    words_metrics[row.word]['relative_incorrect'] = (\n",
    "        (\n",
    "            (\n",
    "                row.antichina_incorrect_w + row.antivacina_incorrect_w + row.provacina_incorrect_w\n",
    "            ) / (\n",
    "                row.antichina_correct_n + row.antivacina_correct_n + row.provacina_correct_n +\\\n",
    "                row.antichina_incorrect_n + row.antivacina_incorrect_n + row.provacina_incorrect_n\n",
    "            )\n",
    "        ) * 100 \n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Now calculate for each group\n",
    "    \n",
    "    for group in ['antichina', 'antivacina', 'provacina']:\n",
    "        \n",
    "        words_metrics[row.word][f'{group}_absolute'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_correct_w'] + row[f'{group}_incorrect_w']\n",
    "                ) / COUNTS[group] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "            ) * 100 \n",
    "        )\n",
    "        \n",
    "        words_metrics[row.word][f'{group}_absolute_correct'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_correct_w']\n",
    "                ) / COUNTS[group] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "            ) * 100 \n",
    "        )\n",
    "        \n",
    "        words_metrics[row.word][f'{group}_absolute_incorrect'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_incorrect_w']\n",
    "                ) / COUNTS[group] # Maybe this should be the sum of ALL WEIGHTS.\n",
    "            ) * 100 \n",
    "        )\n",
    "        \n",
    "        if (row[f'{group}_correct_n'] + row[f'{group}_incorrect_n']) == 0:\n",
    "            break\n",
    "        \n",
    "        words_metrics[row.word][f'{group}_relative'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_correct_w'] + row[f'{group}_incorrect_w']\n",
    "                ) / (\n",
    "                    row[f'{group}_correct_n'] + row[f'{group}_incorrect_n']\n",
    "                )\n",
    "            ) * 100 \n",
    "        )\n",
    "\n",
    "        words_metrics[row.word][f'{group}_relative_correct'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_correct_w']\n",
    "                ) / (\n",
    "                    row[f'{group}_correct_n'] + row[f'{group}_incorrect_n']\n",
    "                )\n",
    "            ) * 100 \n",
    "        )\n",
    "\n",
    "        words_metrics[row.word][f'{group}_relative_incorrect'] = (\n",
    "            (\n",
    "                (\n",
    "                    row[f'{group}_incorrect_w']\n",
    "                ) / (\n",
    "                    row[f'{group}_correct_n'] + row[f'{group}_incorrect_n']\n",
    "                )\n",
    "            ) * 100 \n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_metrics_df = pd.DataFrame(words_metrics).T\n",
    "words_metrics_df.insert(0, column='word', value=words_metrics_df.index)\n",
    "words_metrics_df.to_csv(f'{FOLDER}/words_metrics.csv', index=None)\n",
    "words_metrics_df.sample(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TF-IDF (General and by group)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tfidf_weights = pd.read_csv(f'{FOLDER}/tfidf_weights.csv', sep=';', index_col=0)\n",
    "tfidf_weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "tfidf_indices = pd.read_csv(f'{FOLDER}/tfidf_indices.csv', sep=';', index_col=0)\n",
    "tfidf_indices.antichina = tfidf_indices.antichina.apply(lambda x: literal_eval(x))\n",
    "tfidf_indices.antivacina = tfidf_indices.antivacina.apply(lambda x: literal_eval(x))\n",
    "tfidf_indices.provacina = tfidf_indices.provacina.apply(lambda x: literal_eval(x))\n",
    "\n",
    "tfidf_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for _, row in tfidf_weights.iterrows():\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        words_metrics[row.name]['tfidf'] = np.mean([row[col] for col in tfidf_weights.columns])\n",
    "\n",
    "        for group in ['antichina', 'antivacina', 'provacina']:\n",
    "\n",
    "            group_tfidf_values = [row[index] for index in tfidf_indices[group][0]]\n",
    "\n",
    "            words_metrics[row.name][f'{group}_tfidf'] = np.mean(\n",
    "                group_tfidf_values\n",
    "            )\n",
    "\n",
    "            words_metrics[row.name][f'{group}_tfidf_correct'] = (\n",
    "                np.sum([row[index] for index in tfidf_indices[group][1]]) / len(group_tfidf_values)\n",
    "            )\n",
    "\n",
    "            words_metrics[row.name][f'{group}_tfidf_incorrect'] = (\n",
    "                np.sum([row[index] for index in tfidf_indices[group][2]]) / len(group_tfidf_values)\n",
    "            )\n",
    "    \n",
    "    except:\n",
    "        print('Error with word:', row.name)\n",
    "        raise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_metrics_df = pd.DataFrame(words_metrics).T\n",
    "words_metrics_df.insert(0, column='word', value=words_metrics_df.index)\n",
    "words_metrics_df.to_csv(f'{FOLDER}/words_metrics.csv', index=None)\n",
    "words_metrics_df.sample(5)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "11804bb1f250a85d0267cdde9a53e916113451a0f88a057835fc51e3493d4141"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}