{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics analysis\n",
    "\n",
    "This script gets valuable information from the calculated metrics. Detect possible relevant words and determine their contribution for each group of results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14.4, 10.8]\n",
    "plt.rcParams['figure.dpi'] = 200 # 200 e.g. is really fine, but slower\n",
    "\n",
    "# CHECKPOINT = 'neuralmind/bert-base-portuguese-cased'\n",
    "CHECKPOINT = 'bert-base-multilingual-uncased'\n",
    "FOLDER = './outputs/bert-base-multilingual-uncased'\n",
    "\n",
    "# Create a \"words\" folder to save relevant words\n",
    "Path(f'{FOLDER}/words/').mkdir(parents=True, exist_ok=True)\n",
    "Path(f'{FOLDER}/graphics/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOP_N = 30\n",
    "\n",
    "TOPS = [50, 100, 150, 200, 250, 500]\n",
    "\n",
    "R_W_COLORS = [\n",
    "    '#2d93ad',\n",
    "    '#ff6978',\n",
    "]\n",
    "\n",
    "COLORS = [\n",
    "    '#C7AC92',\n",
    "    '#48E5C2',\n",
    "    '#3D3A4B',\n",
    "]\n",
    "\n",
    "GROUPS = [\n",
    "    'antichina',\n",
    "    'antivacina',\n",
    "    'provacina'\n",
    "]\n",
    "\n",
    "GROUPS_NAMES = {\n",
    "    'antichina': 'Anti-sinovaxxers',\n",
    "    'antivacina': 'Anti-vaxxers',\n",
    "    'provacina': 'Pro-vaxxers',\n",
    "}\n",
    "\n",
    "COUNTS = {}\n",
    "for i, row in pd.read_csv(f'{FOLDER}/result_counts.csv').iterrows():\n",
    "    COUNTS[row['name']] = row['count']\n",
    "print(COUNTS)\n",
    "\n",
    "words_metrics = pd.read_csv(f'{FOLDER}/words_metrics.csv')\n",
    "words_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Words with greatest attention (in general)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "PROPORTION = (\n",
    "    (COUNTS['antichina_correct'] +  COUNTS['antivacina_correct'] + COUNTS['provacina_correct']) /\\\n",
    "    COUNTS['total']\n",
    ")\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(14.4, 8))\n",
    "fig.subplots_adjust(wspace=0.35)\n",
    "\n",
    "axarr[0].set_xlabel('Absolute attention')\n",
    "axarr[1].set_xlabel('Relative attention')\n",
    "\n",
    "absolute_df = words_metrics.sort_values('absolute', ascending=False).head(TOP_N)\n",
    "absolute_df.plot(kind='barh', ax=axarr[0], x='word', y=['absolute_correct', 'absolute_incorrect'], title='Top 30 words with greatest absolute attention', color=[R_W_COLORS[0], R_W_COLORS[1]], stacked=True, legend=None, xlabel='Word')\n",
    "bar = 0\n",
    "thresholds = 0\n",
    "for _, row in absolute_df.iterrows():\n",
    "    if row['absolute_correct'] < PROPORTION * row['absolute']:\n",
    "        if thresholds == 0:\n",
    "            axarr[0].axvline(PROPORTION * row['absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--', label='aa')\n",
    "            thresholds += 1\n",
    "        else:\n",
    "            axarr[0].axvline(PROPORTION * row['absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--')\n",
    "    bar += 1\n",
    "handles, _ = axarr[0].get_legend_handles_labels()\n",
    "axarr[0].legend(handles[1:] + [handles[0]], ['Attention on well-predicted tweets', 'Attention on mispredicted tweets', 'Threshold for misprediction contribution'])\n",
    "\n",
    "relative_df = words_metrics.sort_values('relative', ascending=False).head(TOP_N)\n",
    "relative_df.plot(kind='barh', ax=axarr[1], x='word', y=['relative_correct', 'relative_incorrect'], title='Top 30 words with greatest relative attention', color=[R_W_COLORS[0], R_W_COLORS[1]], stacked=True, legend=None, xlabel='')\n",
    "\n",
    "fig.savefig(f'{FOLDER}/graphics/general.svg', format='svg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Words with greatest attention (by group)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TOP_N = 20\n",
    "\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(14.4, 6.5))\n",
    "\n",
    "for i, group in enumerate(GROUPS):\n",
    "    axarr[i].set_xlabel('Absolute attention')\n",
    "    \n",
    "    group_df = words_metrics.sort_values(f'{group}_absolute', ascending=False).head(TOP_N)\n",
    "    PROPORTION = COUNTS[f'{group}_correct'] / COUNTS[f'{group}']\n",
    "    \n",
    "    bar = 0\n",
    "    thresholds = 0\n",
    "    for _, row in group_df.iterrows():\n",
    "        if row[f'{group}_absolute_correct'] < PROPORTION * row[f'{group}_absolute']:\n",
    "            if thresholds == 0:\n",
    "                axarr[i].axvline(PROPORTION * row[f'{group}_absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--', label='aa')\n",
    "                thresholds += 1\n",
    "            else:\n",
    "                axarr[i].axvline(PROPORTION * row[f'{group}_absolute'], (bar / TOP_N), ((bar + 1)/TOP_N), color='black', linestyle='--')\n",
    "        bar += 1\n",
    "    \n",
    "    group_df.plot(kind='barh', ax=axarr[i], x='word', y=[f'{group}_absolute_correct', f'{group}_absolute_incorrect'], title=GROUPS_NAMES[group], color=[R_W_COLORS[0], R_W_COLORS[1]], stacked=True, legend=None, xlabel='Word')\n",
    "    axarr[i].set_xlim(0, 15)\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.4)\n",
    "fig.savefig(f'{FOLDER}/graphics/groups.svg', format='svg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Get _relevant_, _positive-contributing_ and _existing-in-vocabulary words_..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(CHECKPOINT)\n",
    "vocab_words = list(tokenizer.vocab.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "general_percentages = {}\n",
    "\n",
    "PROPORTION = (\n",
    "    (COUNTS['antichina_correct'] +  COUNTS['antivacina_correct'] + COUNTS['provacina_correct']) /\\\n",
    "    COUNTS['total']\n",
    ")\n",
    "\n",
    "for top in TOPS:\n",
    "    general_percentages[f'general_{top}'] = {\n",
    "        'relevant': 0.0,\n",
    "        'correct': 0.0,\n",
    "        'in_vocabulary': 0.0,\n",
    "    }\n",
    "    \n",
    "    print(f'TOP {top}:')\n",
    "    \n",
    "    tfidf = words_metrics.sort_values('tfidf', ascending=False).head(top)\n",
    "    absolute_df = words_metrics.sort_values('absolute', ascending=False).head(top)\n",
    "    np.savetxt(f'{FOLDER}/words/general_{top}.txt', absolute_df.word.values, delimiter=',', newline='\\n', fmt=\"%s\")\n",
    "    \n",
    "    if top == 500:\n",
    "        absolute_df.to_csv(f'{FOLDER}/words/general_{top}.csv', sep=';', index=None)\n",
    "    \n",
    "    intersection = set(absolute_df.word).intersection(set(tfidf.word))\n",
    "    percentage = len(intersection) / top * 100\n",
    "    np.savetxt(f'{FOLDER}/words/general_relevant_{top}.txt', list(intersection), delimiter=',', newline='\\n', fmt=\"%s\")\n",
    "    general_percentages[f'general_{top}']['relevant'] = percentage\n",
    "    print(f'Relevant words based on TFIDF: {percentage}%')\n",
    "#     print(intersection)\n",
    "    \n",
    "    absolute_correct = absolute_df[absolute_df.absolute_correct < PROPORTION * absolute_df.absolute]\n",
    "    \n",
    "    intersection = set(absolute_df.word).intersection(set(absolute_correct.word))\n",
    "    percentage = len(intersection) / top * 100\n",
    "    np.savetxt(f'{FOLDER}/words/general_correct_{top}.txt', list(intersection), delimiter=',', newline='\\n', fmt=\"%s\")\n",
    "    general_percentages[f'general_{top}']['correct'] = percentage\n",
    "    print(f'Words that contribute to correctness: {percentage}%')\n",
    "#     print(intersection)\n",
    "\n",
    "    words_present_in_vocab = 0\n",
    "    for word in list(absolute_df.word):\n",
    "        if word in vocab_words:\n",
    "            words_present_in_vocab += 1\n",
    "    percentage = words_present_in_vocab / top * 100\n",
    "    general_percentages[f'general_{top}']['in_vocabulary'] = percentage\n",
    "    print(f'Words in vocabulary: {percentage}%')\n",
    "    print('')\n",
    "\n",
    "\n",
    "percentages_df = pd.DataFrame(general_percentages).T\n",
    "percentages_df.insert(0, column='top', value=percentages_df.index)\n",
    "percentages_df.to_csv(f'{FOLDER}/words/general_percentages.csv', index=None, sep=';')\n",
    "percentages_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "group_percentages = {}\n",
    "\n",
    "for group in GROUPS:\n",
    "\n",
    "    group_df = words_metrics.sort_values(f'{group}_absolute', ascending=False).head(TOP_N)\n",
    "    PROPORTION = COUNTS[f'{group}_correct'] / COUNTS[f'{group}']\n",
    "    \n",
    "    for top in TOPS:\n",
    "        group_percentages[f'{group}_{top}'] = {\n",
    "            'relevant': 0.0,\n",
    "            'correct': 0.0,\n",
    "        }\n",
    "\n",
    "        tfidf = words_metrics.sort_values(f'{group}_tfidf', ascending=False).head(top)\n",
    "        absolute = words_metrics.sort_values(f'{group}_absolute', ascending=False).head(top)\n",
    "\n",
    "        intersection = set(absolute.word).intersection(set(tfidf.word))\n",
    "        percentage = len(intersection) / top * 100\n",
    "        np.savetxt(f'{FOLDER}/words/{group}_relevant_{top}.txt', list(intersection), delimiter=',', newline='\\n', fmt=\"%s\")\n",
    "        group_percentages[f'{group}_{top}']['relevant'] = percentage\n",
    "\n",
    "        absolute_correct = absolute[absolute[f'{group}_absolute_correct'] < PROPORTION * absolute[f'{group}_absolute']]\n",
    "\n",
    "        intersection = set(absolute_df.word).intersection(set(absolute_correct.word))\n",
    "        percentage = len(intersection) / top * 100\n",
    "        np.savetxt(f'{FOLDER}/words/{group}_correct_{top}.txt', list(intersection), delimiter=',', newline='\\n', fmt=\"%s\")\n",
    "        group_percentages[f'{group}_{top}']['correct'] = percentage\n",
    "\n",
    "percentages_df = pd.DataFrame(group_percentages).T\n",
    "percentages_df.insert(0, column='top', value=percentages_df.index)\n",
    "percentages_df.to_csv(f'{FOLDER}/words/groups_percentages.csv', index=None, sep=';')\n",
    "percentages_df"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}