{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Words and Tokens attention calculation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Loading weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import string\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "LABEL_MAPPER = [\n",
    "    'antichina',\n",
    "    'antivacina',\n",
    "    'provacina',\n",
    "]\n",
    "\n",
    "CHECKPOINT = 'neuralmind/bert-base-portuguese-cased'\n",
    "FOLDER = './results/'\n",
    "\n",
    "attention_weights = torch.load(f'{FOLDER}/explanations.pt')\n",
    "results_df = pd.read_csv(f'{FOLDER}/test_results_complete.csv', sep=';')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "results_df['words'] = results_df['words'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "results_df['tokens'] = results_df['tokens'].apply(lambda x: x.split())\n",
    "\n",
    "results_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Just for testing...\n",
    "for i, row in results_df.sample(5).iterrows():\n",
    "    tokens = row.tokens\n",
    "    weights = attention_weights[i]\n",
    "    print(tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens), skip_special_tokens=True))\n",
    "    if len(tokens) != len(weights):\n",
    "        print(f\"Doesn't match on tweet: `{row.tweet}` ({len(tokens)} vs {len(weights)})\")\n",
    "    print('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Save results counts..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "counts = {}\n",
    "\n",
    "counts['antichina_correct'] = len(results_df.loc[(results_df.got == 0) & (results_df.expected == results_df.got)])\n",
    "counts['antichina_wrong'] = len(results_df.loc[(results_df.got == 0) & (results_df.expected != results_df.got)])\n",
    "counts['antichina'] = counts['antichina_correct'] + counts['antichina_wrong']\n",
    "\n",
    "counts['antivacina_correct'] = len(results_df.loc[(results_df.got == 1) & (results_df.expected == results_df.got)])\n",
    "counts['antivacina_wrong'] = len(results_df.loc[(results_df.got == 1) & (results_df.expected != results_df.got)])\n",
    "counts['antivacina'] = counts['antivacina_correct'] + counts['antivacina_wrong']\n",
    "\n",
    "counts['provacina_correct'] = len(results_df.loc[(results_df.got == 2) & (results_df.expected == results_df.got)])\n",
    "counts['provacina_wrong'] = len(results_df.loc[(results_df.got == 2) & (results_df.expected != results_df.got)])\n",
    "counts['provacina'] = counts['provacina_correct'] + counts['provacina_wrong']\n",
    "\n",
    "counts['total'] = counts['antichina'] + counts['antivacina'] + counts['provacina']\n",
    "\n",
    "counts_df = pd.DataFrame(\n",
    "    columns = ['name', 'count'],\n",
    "    data = [ (key, value) for key, value in counts.items() ]\n",
    ")\n",
    "counts_df.to_csv(f'{FOLDER}/result_counts.csv', index=None)\n",
    "counts_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "counts = {}\n",
    "\n",
    "counts['antichina_antichina'] = len(results_df.loc[(results_df.expected == 0) & (results_df.got == 0)])\n",
    "counts['antichina_antivacina'] = len(results_df.loc[(results_df.expected == 0) & (results_df.got == 1)])\n",
    "counts['antichina_provacina'] = len(results_df.loc[(results_df.expected == 0) & (results_df.got == 2)])\n",
    "\n",
    "counts['antivacina_antichina'] = len(results_df.loc[(results_df.expected == 1) & (results_df.got == 0)])\n",
    "counts['antivacina_antivacina'] = len(results_df.loc[(results_df.expected == 1) & (results_df.got == 1)])\n",
    "counts['antivacina_provacina'] = len(results_df.loc[(results_df.expected == 1) & (results_df.got == 2)])\n",
    "\n",
    "counts['provacina_antichina'] = len(results_df.loc[(results_df.expected == 2) & (results_df.got == 0)])\n",
    "counts['provacina_antivacina'] = len(results_df.loc[(results_df.expected == 2) & (results_df.got == 1)])\n",
    "counts['provacina_provacina'] = len(results_df.loc[(results_df.expected == 2) & (results_df.got == 2)])\n",
    "\n",
    "counts_df = pd.DataFrame(\n",
    "    columns = ['name', 'count'],\n",
    "    data = [ (key, value) for key, value in counts.items() ]\n",
    ")\n",
    "counts_df.to_csv(f'{FOLDER}/result_statistics.csv', index=None)\n",
    "counts_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Attentions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1) Function to map tokens and weights to words\n",
    "Calculates different attention weights for the words on each sentence\n",
    "It employs:\n",
    "- The tokens of each tweet\n",
    "- The attention obtained by each token in the tweet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Considerations:\n",
    "# - A word can appear multiple times in the same tweet,\n",
    "#   or in many tweets, it is going to be counted each\n",
    "#   appearance.\n",
    "\n",
    "def add_word_weight_to_mapping(\n",
    "    words,\n",
    "    word,\n",
    "    tokens,\n",
    "    weight,\n",
    "    gotten,\n",
    "    expected\n",
    "):\n",
    "    if word not in words:\n",
    "        words[word] = {\n",
    "            'tokens': ' '.join(tokens),\n",
    "            'antichina_correct_w': 0.0,\n",
    "            'antichina_correct_n': 0,\n",
    "            'antichina_incorrect_w': 0.0,\n",
    "            'antichina_incorrect_n': 0,\n",
    "\n",
    "            'antivacina_correct_w': 0.0,\n",
    "            'antivacina_correct_n': 0,\n",
    "            'antivacina_incorrect_w': 0.0,\n",
    "            'antivacina_incorrect_n': 0,\n",
    "\n",
    "            'provacina_correct_w': 0.0,\n",
    "            'provacina_correct_n': 0,\n",
    "            'provacina_incorrect_w': 0.0,\n",
    "            'provacina_incorrect_n': 0,\n",
    "        }\n",
    "    words[word][\n",
    "        f\"{LABEL_MAPPER[gotten]}_{'correct' if gotten == expected else 'incorrect'}_w\"\n",
    "    ] += weight\n",
    "    words[word][\n",
    "        f\"{LABEL_MAPPER[gotten]}_{'correct' if gotten == expected else 'incorrect'}_n\"\n",
    "    ] += 1\n",
    "    \n",
    "    return words\n",
    "    \n",
    "\n",
    "def get_words_attentions(\n",
    "    words_map,\n",
    "    tokens,\n",
    "    weights,\n",
    "    gotten_label,\n",
    "    expected_label\n",
    "):\n",
    "    current_sub_text_indices = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        try:\n",
    "            if token in tokenizer.all_special_tokens:\n",
    "                continue\n",
    "\n",
    "            if not token.startswith('##') and len(current_sub_text_indices):\n",
    "                word = \" \".join(\n",
    "                    [tokens[idx] for idx in current_sub_text_indices]\n",
    "                ).replace(\" ##\", \"\").strip()\n",
    "                average_attention = np.mean([weights[idx] for idx in current_sub_text_indices])\n",
    "                \n",
    "                words_map = add_word_weight_to_mapping(\n",
    "                    words_map,\n",
    "                    word,\n",
    "                    [tokens[idx] for idx in current_sub_text_indices],\n",
    "                    average_attention,\n",
    "                    gotten_label,\n",
    "                    expected_label\n",
    "                )\n",
    "                \n",
    "                current_sub_text_indices = []\n",
    "\n",
    "            current_sub_text_indices.append(i)\n",
    "        except:\n",
    "            print(i, token)\n",
    "            print(current_sub_text_indices)\n",
    "            raise\n",
    "        \n",
    "        \n",
    "    if len(current_sub_text_indices):\n",
    "        word = \" \".join(\n",
    "                    [tokens[idx] for idx in current_sub_text_indices]\n",
    "                ).replace(\" ##\", \"\").strip()\n",
    "        average_attention = np.mean([weights[idx] for idx in current_sub_text_indices])\n",
    "        \n",
    "        words_map = add_word_weight_to_mapping(\n",
    "            words_map,\n",
    "            word,\n",
    "            [tokens[idx] for idx in current_sub_text_indices],\n",
    "            average_attention,\n",
    "            gotten_label,\n",
    "            expected_label\n",
    "        )\n",
    "        \n",
    "    return words_map"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2) Function to map weights to tokens\n",
    "Calculates different attention weights for the tokens on each sentence\n",
    "It employs:\n",
    "- The attention obtained by each token in the tweet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Considerations:\n",
    "# - A token can appear multiple times in the same tweet,\n",
    "#   or in many tweets, it is going to be counted each\n",
    "#   time it appears.\n",
    "\n",
    "def add_token_weight_to_mapping(\n",
    "    tokens,\n",
    "    token,\n",
    "    weight,\n",
    "    gotten,\n",
    "    expected\n",
    "):\n",
    "    if token not in tokens:\n",
    "        tokens[token] = {\n",
    "            'antichina_correct_w': 0.0,\n",
    "            'antichina_correct_n': 0,\n",
    "            'antichina_incorrect_w': 0.0,\n",
    "            'antichina_incorrect_n': 0,\n",
    "\n",
    "            'antivacina_correct_w': 0.0,\n",
    "            'antivacina_correct_n': 0,\n",
    "            'antivacina_incorrect_w': 0.0,\n",
    "            'antivacina_incorrect_n': 0,\n",
    "\n",
    "            'provacina_correct_w': 0.0,\n",
    "            'provacina_correct_n': 0,\n",
    "            'provacina_incorrect_w': 0.0,\n",
    "            'provacina_incorrect_n': 0,\n",
    "        }\n",
    "    tokens[token][\n",
    "        f\"{LABEL_MAPPER[gotten]}_{'correct' if gotten == expected else 'incorrect'}_w\"\n",
    "    ] += weight\n",
    "    tokens[token][\n",
    "        f\"{LABEL_MAPPER[gotten]}_{'correct' if gotten == expected else 'incorrect'}_n\"\n",
    "    ] += 1\n",
    "    \n",
    "    return tokens\n",
    "    \n",
    "\n",
    "def get_tokens_attentions(\n",
    "    tokens_map,\n",
    "    tokens,\n",
    "    weights,\n",
    "    gotten_label,\n",
    "    expected_label\n",
    "):\n",
    "    current_sub_text_indices = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        try:\n",
    "            if token in tokenizer.all_special_tokens:\n",
    "                continue\n",
    "                \n",
    "            tokens_map = add_token_weight_to_mapping(\n",
    "                tokens_map,\n",
    "                token,\n",
    "                weights[i],\n",
    "                gotten_label,\n",
    "                expected_label\n",
    "            )\n",
    "        except:\n",
    "            print(i, token)\n",
    "            raise        \n",
    "\n",
    "    return tokens_map"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3) Caculations..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_map = {}\n",
    "tokens_map = {}\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    try:\n",
    "        words_map = get_words_attentions(\n",
    "            words_map,\n",
    "            row.tokens,\n",
    "            attention_weights[i],\n",
    "            row.got,\n",
    "            row.expected\n",
    "        )\n",
    "        \n",
    "        tokens_map = get_tokens_attentions(\n",
    "            tokens_map,\n",
    "            row.tokens,\n",
    "            attention_weights[i],\n",
    "            row.got,\n",
    "            row.expected\n",
    "        )\n",
    "    except:\n",
    "        print(f'Error found in {i}: {row.tweet}')\n",
    "        print(len(row.tokens), len(attention_weights[i]))\n",
    "        print(row.tokens)\n",
    "        print(attention_weights[i])\n",
    "        print('')\n",
    "        raise\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.4) Save words attentions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "words_df = pd.DataFrame(words_map).T.sort_index()\n",
    "words_df.insert(0, column='word', value=words_df.index)\n",
    "words_df.to_csv(f'{FOLDER}/words_attention.csv', index=None, sep=';')\n",
    "words_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.5) Save tokens attentions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokens_df = pd.DataFrame(tokens_map).T.sort_index()\n",
    "tokens_df.insert(0, column='token', value=tokens_df.index)\n",
    "tokens_df.to_csv(f'{FOLDER}/tokens_attention.csv', index=None, sep=';')\n",
    "tokens_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4) TF-IDF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "STOPWORDS = nltk.corpus.stopwords.words('portuguese') + list(string.punctuation)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "#     strip_accents='ascii', # This is OPTIONAL\n",
    "    stop_words=STOPWORDS,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "vectors = vectorizer.fit_transform(results_df.words.values)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "tf_idf = pd.DataFrame(\n",
    "    denselist,\n",
    "    columns=feature_names\n",
    ").T\n",
    "\n",
    "# Save TF-IDF weights for each word\n",
    "tf_idf.to_csv(f'{FOLDER}/tfidf_weights.csv', sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the indices of tweets of each group\n",
    "antichina = results_df[results_df.expected == 0]\n",
    "antivacina = results_df[results_df.expected == 1]\n",
    "provacina = results_df[results_df.expected == 2]\n",
    "\n",
    "indices = {\n",
    "    'antichina': {\n",
    "        'all': list(antichina.index),\n",
    "        'correct': list(antichina[antichina.got == antichina.expected].index),\n",
    "        'wrong': list(antichina[antichina.got != antichina.expected].index),\n",
    "    },\n",
    "    'antivacina': {\n",
    "        'all': list(antivacina.index),\n",
    "        'correct': list(antivacina[antivacina.got == antivacina.expected].index),\n",
    "        'wrong': list(antivacina[antivacina.got != antivacina.expected].index),\n",
    "    },\n",
    "    'provacina': {\n",
    "        'all': list(provacina.index),\n",
    "        'correct': list(provacina[provacina.got == provacina.expected].index),\n",
    "        'wrong': list(provacina[provacina.got != provacina.expected].index),\n",
    "    },\n",
    "}\n",
    "\n",
    "indices_df = pd.DataFrame(indices)\n",
    "indices_df.insert(0, column='group', value=indices_df.index)\n",
    "indices_df.to_csv(f'{FOLDER}/tfidf_indices.csv', sep=';', index=None)\n",
    "indices_df"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "11804bb1f250a85d0267cdde9a53e916113451a0f88a057835fc51e3493d4141"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}